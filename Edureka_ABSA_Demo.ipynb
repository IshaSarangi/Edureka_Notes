{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnyKteyWuMlUqaMUvd3WXB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f533ab7eb1348478b9c77ae7a5c8d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f86006caa5574d229e0ca2bbdaec3438",
              "IPY_MODEL_9fc7f35693ba4b85950a9316a44582d5",
              "IPY_MODEL_5d48d2051f004c69a312b1ac2b9ef6c5"
            ],
            "layout": "IPY_MODEL_20b915ddc70f4a398054504ad0f0d0b6"
          }
        },
        "f86006caa5574d229e0ca2bbdaec3438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c41f85b94448438ca72369301704f791",
            "placeholder": "​",
            "style": "IPY_MODEL_1b74cd987f7b4b48bc533b8548455185",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9fc7f35693ba4b85950a9316a44582d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2dab7d52d84bd6b9247c6e47e406fd",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de478aad0b504a3286261156a947a848",
            "value": 48
          }
        },
        "5d48d2051f004c69a312b1ac2b9ef6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee68da2192644f79aaad332c3dfe9492",
            "placeholder": "​",
            "style": "IPY_MODEL_c04dd9c9156d4b2194bfc6138b5d88d6",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.34kB/s]"
          }
        },
        "20b915ddc70f4a398054504ad0f0d0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41f85b94448438ca72369301704f791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b74cd987f7b4b48bc533b8548455185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca2dab7d52d84bd6b9247c6e47e406fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de478aad0b504a3286261156a947a848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee68da2192644f79aaad332c3dfe9492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04dd9c9156d4b2194bfc6138b5d88d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e124db89f1646838c4896b292f3b9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74bedb075db54fa7aafcd9de216e4f64",
              "IPY_MODEL_a81409c998174e65bb2aa4c2ff087070",
              "IPY_MODEL_2a5c3836d3ec4bacbcbd5bf5fd0f0225"
            ],
            "layout": "IPY_MODEL_a580d60f65894efe8710c968fbdd81a3"
          }
        },
        "74bedb075db54fa7aafcd9de216e4f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4f57eb21a54b46bd85b8dda1dd0107",
            "placeholder": "​",
            "style": "IPY_MODEL_2c38405a95f44607a1fcb78af6e7cdf5",
            "value": "vocab.txt: 100%"
          }
        },
        "a81409c998174e65bb2aa4c2ff087070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bfeaf5da0284116895132858f1c2bdd",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeaaa2ce400e4f47ba583b7441e36a06",
            "value": 231508
          }
        },
        "2a5c3836d3ec4bacbcbd5bf5fd0f0225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240f2aca6c7f47ceb4a5a30e74228365",
            "placeholder": "​",
            "style": "IPY_MODEL_3cd4df20d7a243b68aff9e47816a01f1",
            "value": " 232k/232k [00:00&lt;00:00, 7.47MB/s]"
          }
        },
        "a580d60f65894efe8710c968fbdd81a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4f57eb21a54b46bd85b8dda1dd0107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c38405a95f44607a1fcb78af6e7cdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bfeaf5da0284116895132858f1c2bdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeaaa2ce400e4f47ba583b7441e36a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "240f2aca6c7f47ceb4a5a30e74228365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd4df20d7a243b68aff9e47816a01f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2be1739952c4157a990e7026be01971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa402649de1b4c9d8aa78e296d34775c",
              "IPY_MODEL_74551b36046a458c981538ca406742bf",
              "IPY_MODEL_570a3e3627884aacb845658e25cb14c9"
            ],
            "layout": "IPY_MODEL_2ad97a1feda34105bdb95d4c899a836d"
          }
        },
        "aa402649de1b4c9d8aa78e296d34775c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9cf35104f14aecb8a40eb71061ed7f",
            "placeholder": "​",
            "style": "IPY_MODEL_dc44ae1907da413695b25bc6c503717c",
            "value": "tokenizer.json: 100%"
          }
        },
        "74551b36046a458c981538ca406742bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c30f604b9c430584b1373a854fa692",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9909d9897e6544a894e20cc714e1f866",
            "value": 466062
          }
        },
        "570a3e3627884aacb845658e25cb14c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdf21bc57ea4651b188b431ea6b0fab",
            "placeholder": "​",
            "style": "IPY_MODEL_03fdeb48d03b499e9e9956d3c6ccfd2d",
            "value": " 466k/466k [00:00&lt;00:00, 32.8MB/s]"
          }
        },
        "2ad97a1feda34105bdb95d4c899a836d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9cf35104f14aecb8a40eb71061ed7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc44ae1907da413695b25bc6c503717c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c30f604b9c430584b1373a854fa692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9909d9897e6544a894e20cc714e1f866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fdf21bc57ea4651b188b431ea6b0fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03fdeb48d03b499e9e9956d3c6ccfd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f3e269d84044c8696180fbd04420687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13cd8146ef96436884271118d8101199",
              "IPY_MODEL_34b5727f9a7f4fe6b718e7605cdf0388",
              "IPY_MODEL_3bdddfbe9898493181eb254dba454c32"
            ],
            "layout": "IPY_MODEL_66043872589549feb18092163c1d0e82"
          }
        },
        "13cd8146ef96436884271118d8101199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd86228e5dc4cf688654e366786080a",
            "placeholder": "​",
            "style": "IPY_MODEL_e4c1734bec164b109d1eeb9e98c3f554",
            "value": "config.json: 100%"
          }
        },
        "34b5727f9a7f4fe6b718e7605cdf0388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e5acbffd6746f3b50fb3a8de507f36",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd7b8e4d957c480f8c2408e68402cfc6",
            "value": 570
          }
        },
        "3bdddfbe9898493181eb254dba454c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd314cee44124ba3adff91e8c57fdda6",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec3d5f7d82045b98764351774ad2a79",
            "value": " 570/570 [00:00&lt;00:00, 57.6kB/s]"
          }
        },
        "66043872589549feb18092163c1d0e82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd86228e5dc4cf688654e366786080a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c1734bec164b109d1eeb9e98c3f554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7e5acbffd6746f3b50fb3a8de507f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd7b8e4d957c480f8c2408e68402cfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd314cee44124ba3adff91e8c57fdda6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec3d5f7d82045b98764351774ad2a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b264c7770d4eefbcead709b6a2f814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39c7e809dea643808d54c280ad4723a8",
              "IPY_MODEL_3963b4495b4b429599e48f0b315a3f09",
              "IPY_MODEL_9231180ae19f42e49d1ae0d4db61ca45"
            ],
            "layout": "IPY_MODEL_e08ab94bde784c2496fe1cefd4c3a76b"
          }
        },
        "39c7e809dea643808d54c280ad4723a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92fa2c1f20d14fa1b3789f8a4dc20420",
            "placeholder": "​",
            "style": "IPY_MODEL_248b02c103a94df980d8f343a2bef538",
            "value": "model.safetensors: 100%"
          }
        },
        "3963b4495b4b429599e48f0b315a3f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a31921af0849a88a7cc26fd497b415",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_801d18f751404b3b85ae585e9476bc77",
            "value": 440449768
          }
        },
        "9231180ae19f42e49d1ae0d4db61ca45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6875783911cf4d5ab0be17a85eb88fe7",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f2d5cab0f84c25b42ef5e9ff88d096",
            "value": " 440M/440M [00:11&lt;00:00, 58.4MB/s]"
          }
        },
        "e08ab94bde784c2496fe1cefd4c3a76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92fa2c1f20d14fa1b3789f8a4dc20420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248b02c103a94df980d8f343a2bef538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4a31921af0849a88a7cc26fd497b415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801d18f751404b3b85ae585e9476bc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6875783911cf4d5ab0be17a85eb88fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f2d5cab0f84c25b42ef5e9ff88d096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56399a1a67e9441d9ba32e65b515f224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_223d25a13a2943e58a2ed04952df8c49",
              "IPY_MODEL_27b4c1b7c1504179a7b213bb6f879d0a",
              "IPY_MODEL_ff9a5d98e17e4c71ac80d9e7abb2f64a"
            ],
            "layout": "IPY_MODEL_5eaeafc34f4a4034a951295f9f0aff36"
          }
        },
        "223d25a13a2943e58a2ed04952df8c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f15cfa8ad54c0fbeaa0fa6a9017a61",
            "placeholder": "​",
            "style": "IPY_MODEL_5880fc7f6a2b400786ae726620f7ba0f",
            "value": "config.json: "
          }
        },
        "27b4c1b7c1504179a7b213bb6f879d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87801c4aa1184a498c4eed8e717016d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa0fb66660a945cd814ed24863e73cdd",
            "value": 1
          }
        },
        "ff9a5d98e17e4c71ac80d9e7abb2f64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337fef1191d24ad9be7ae71a4a5eeb3b",
            "placeholder": "​",
            "style": "IPY_MODEL_6d188f1183234cad91ddb7f3a3305016",
            "value": " 1.03k/? [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "5eaeafc34f4a4034a951295f9f0aff36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f15cfa8ad54c0fbeaa0fa6a9017a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5880fc7f6a2b400786ae726620f7ba0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87801c4aa1184a498c4eed8e717016d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fa0fb66660a945cd814ed24863e73cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "337fef1191d24ad9be7ae71a4a5eeb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d188f1183234cad91ddb7f3a3305016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee773e54027b491d9e76537f84cf067c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a13efa9fddc4ade8bd797c03b3979db",
              "IPY_MODEL_986765e390a64bc8854d26901d8fd070",
              "IPY_MODEL_fe18a3f8e9b246fa91faa5b6f6115f03"
            ],
            "layout": "IPY_MODEL_06a33f4a30d649c7bdff0deceb46fdf5"
          }
        },
        "7a13efa9fddc4ade8bd797c03b3979db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd4682bb960a4bd3922423805cc5c099",
            "placeholder": "​",
            "style": "IPY_MODEL_b2ab4f4ff105457291387481778f6c3e",
            "value": "model.safetensors: 100%"
          }
        },
        "986765e390a64bc8854d26901d8fd070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3378aa1791b54f9baf60e8b835fde13a",
            "max": 737726548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4657fe3a3fe2424ebc67cc61b81f95d1",
            "value": 737726548
          }
        },
        "fe18a3f8e9b246fa91faa5b6f6115f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd03dcc3bfa64f8ab15be073285f5c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_c8f4b4e1027a46659e5ec1674e5e9c99",
            "value": " 738M/738M [00:19&lt;00:00, 56.6MB/s]"
          }
        },
        "06a33f4a30d649c7bdff0deceb46fdf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd4682bb960a4bd3922423805cc5c099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2ab4f4ff105457291387481778f6c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3378aa1791b54f9baf60e8b835fde13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4657fe3a3fe2424ebc67cc61b81f95d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd03dcc3bfa64f8ab15be073285f5c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f4b4e1027a46659e5ec1674e5e9c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ee22e4d957943ac9459acfc0fefa4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a8aaee9a41045f388f23a84d7171f8c",
              "IPY_MODEL_4744affb2ddc4cb7bc4ce275e0dc63d8",
              "IPY_MODEL_f94be7352e734970a6b7b6c6229eb25a"
            ],
            "layout": "IPY_MODEL_541159f151474abba4bbd12c4fff185e"
          }
        },
        "0a8aaee9a41045f388f23a84d7171f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be5c8e1f39f4c9bb96a8b76455ae680",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd5edd5e7714de38712ede6c1e07728",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4744affb2ddc4cb7bc4ce275e0dc63d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4e42b1d990246178a58352a8eeb5fd6",
            "max": 372,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d6c1ab74064b43b1c158c62e2dbcd3",
            "value": 372
          }
        },
        "f94be7352e734970a6b7b6c6229eb25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3825c53c6cd240fb82fe124cd270c85e",
            "placeholder": "​",
            "style": "IPY_MODEL_f9d342d42bde43cbac8d90007effdcd9",
            "value": " 372/372 [00:00&lt;00:00, 7.46kB/s]"
          }
        },
        "541159f151474abba4bbd12c4fff185e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be5c8e1f39f4c9bb96a8b76455ae680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd5edd5e7714de38712ede6c1e07728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4e42b1d990246178a58352a8eeb5fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d6c1ab74064b43b1c158c62e2dbcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3825c53c6cd240fb82fe124cd270c85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d342d42bde43cbac8d90007effdcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db49a09d0bb945838ee4316d7351114a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b9420392c3348bc9e97d00ab1366e65",
              "IPY_MODEL_cb87cbea21264eabaa8620f2c0453afc",
              "IPY_MODEL_73d237d8fa00422d85ecd49e65b16ccc"
            ],
            "layout": "IPY_MODEL_0da1e67897ab496187708bd61335b3ed"
          }
        },
        "9b9420392c3348bc9e97d00ab1366e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87314612a7414e5d9ee7b3aae47e35fc",
            "placeholder": "​",
            "style": "IPY_MODEL_5e2e802020894eabb9238dce054f64de",
            "value": "spm.model: 100%"
          }
        },
        "cb87cbea21264eabaa8620f2c0453afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b73b4ec8fa0433aaf8a5b2d4e04c6f3",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f69267c135614a9ba391cc2ab662ee43",
            "value": 2464616
          }
        },
        "73d237d8fa00422d85ecd49e65b16ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_767afe5d4f4946ed93ae9ad06d6ff8ac",
            "placeholder": "​",
            "style": "IPY_MODEL_32897fa3efa1487c8b85f43855451ab7",
            "value": " 2.46M/2.46M [00:00&lt;00:00, 9.33MB/s]"
          }
        },
        "0da1e67897ab496187708bd61335b3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87314612a7414e5d9ee7b3aae47e35fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e2e802020894eabb9238dce054f64de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b73b4ec8fa0433aaf8a5b2d4e04c6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69267c135614a9ba391cc2ab662ee43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "767afe5d4f4946ed93ae9ad06d6ff8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32897fa3efa1487c8b85f43855451ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b50ba8f796645f29986c0f4be46d978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76e4455f15ce42af895c037221a684b4",
              "IPY_MODEL_b40f502029e242799e8fde8773070975",
              "IPY_MODEL_0fcbc732b3864be28e33479fe7970071"
            ],
            "layout": "IPY_MODEL_b2181ac462664eaf96b843efd5960680"
          }
        },
        "76e4455f15ce42af895c037221a684b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91e21acb5f74f19a3ac5e207f6f9b81",
            "placeholder": "​",
            "style": "IPY_MODEL_51cafd0e3640442495cc0f0b40fb6ae6",
            "value": "added_tokens.json: 100%"
          }
        },
        "b40f502029e242799e8fde8773070975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f9eba54b934c17b65c756d9e551ce0",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bd143d89aa349e3942d3b05883a1d24",
            "value": 18
          }
        },
        "0fcbc732b3864be28e33479fe7970071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5851bde868624ccaa943a25d53f95c88",
            "placeholder": "​",
            "style": "IPY_MODEL_9632bb86900744f9b03bdec7ea0604d2",
            "value": " 18.0/18.0 [00:00&lt;00:00, 241B/s]"
          }
        },
        "b2181ac462664eaf96b843efd5960680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91e21acb5f74f19a3ac5e207f6f9b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cafd0e3640442495cc0f0b40fb6ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11f9eba54b934c17b65c756d9e551ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd143d89aa349e3942d3b05883a1d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5851bde868624ccaa943a25d53f95c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9632bb86900744f9b03bdec7ea0604d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "883660c4320248ef9515a48d835f8449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1efc23ad4c674bf29c56c9522c2b2b82",
              "IPY_MODEL_9dd558e9ed71403ead059444b9ed4a63",
              "IPY_MODEL_f9f8568640384758b38720445aeadef2"
            ],
            "layout": "IPY_MODEL_ee7c2318ec044fdeb30e994209a1e803"
          }
        },
        "1efc23ad4c674bf29c56c9522c2b2b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217fe649434247a48f78fbeb0ac9f055",
            "placeholder": "​",
            "style": "IPY_MODEL_a63b48d1115d4170bd9d26642d973193",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9dd558e9ed71403ead059444b9ed4a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a19f0da689407eac316dc1f8142462",
            "max": 156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4094f978fd324dc3b9c81cc1326a14b5",
            "value": 156
          }
        },
        "f9f8568640384758b38720445aeadef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a9ac5131504f53987931fe5d26a44e",
            "placeholder": "​",
            "style": "IPY_MODEL_1dcf14de1e5642bdbd38813596b32e23",
            "value": " 156/156 [00:00&lt;00:00, 2.58kB/s]"
          }
        },
        "ee7c2318ec044fdeb30e994209a1e803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217fe649434247a48f78fbeb0ac9f055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63b48d1115d4170bd9d26642d973193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64a19f0da689407eac316dc1f8142462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4094f978fd324dc3b9c81cc1326a14b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5a9ac5131504f53987931fe5d26a44e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dcf14de1e5642bdbd38813596b32e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaSarangi/Edureka_Notes/blob/main/Edureka_ABSA_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An E-commerce wants to go beyond the traditonal sentiment analysis (P/N) and wants to build a find grained sentiment analysis system that analyzes what customers really feel about the different aspects of products."
      ],
      "metadata": {
        "id": "-1J0ZRtauxUw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "G3JHTLISue27",
        "outputId": "68796f48-f28f-4e0f-9da0-3b9c50bbeaa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     review       aspect sentiment\n",
              "0                   The camera is terrible.       camera  negative\n",
              "1          I'm disappointed with the price.        price  negative\n",
              "2  The performance is neither good nor bad.  performance   neutral\n",
              "3     Excellent design and worth the price.       design  positive\n",
              "4         Nothing special about the screen.       screen   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7864edf-7b84-4c05-8632-2fb2f19b5c53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>aspect</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The camera is terrible.</td>\n",
              "      <td>camera</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm disappointed with the price.</td>\n",
              "      <td>price</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The performance is neither good nor bad.</td>\n",
              "      <td>performance</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent design and worth the price.</td>\n",
              "      <td>design</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nothing special about the screen.</td>\n",
              "      <td>screen</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7864edf-7b84-4c05-8632-2fb2f19b5c53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7864edf-7b84-4c05-8632-2fb2f19b5c53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7864edf-7b84-4c05-8632-2fb2f19b5c53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f9c267ea-1dae-4fb6-8254-65a01d7c4add\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c267ea-1dae-4fb6-8254-65a01d7c4add')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f9c267ea-1dae-4fb6-8254-65a01d7c4add button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 72,\n        \"samples\": [\n          \"Nothing special about the screen.\",\n          \"Highly satisfied with the performance.\",\n          \"The performance is okay.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"camera\",\n          \"price\",\n          \"battery\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Load dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/synthetic_absa_dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['aspect'].value_counts())"
      ],
      "metadata": {
        "id": "KvQ0F4_SvCln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecd77ee-4958-4b2e-a53d-d776e170b6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aspect\n",
            "performance    192\n",
            "price          177\n",
            "battery        173\n",
            "screen         157\n",
            "design         151\n",
            "camera         150\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(x='sentiment', data=df, hue='aspect')\n",
        "plt.title(\"Aspect wise sentiment distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3P-MhQNoZWL6",
        "outputId": "6904553e-93fc-4700-a892-2d4e99f81c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare text pairs (Aspect: Sentiments) for the model's input\n",
        "df['input_pair'] = df.apply(lambda x: f\"What is the sentiment about the {x['aspect']} ? [SEP] {x['review']}\", axis = 1)\n",
        "df[['input_pair', 'sentiment']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cq1kl-nKZljg",
        "outputId": "b406567d-4559-4b78-e79e-393c324d349d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          input_pair sentiment\n",
              "0  What is the sentiment about the camera ? [SEP]...  negative\n",
              "1  What is the sentiment about the price ? [SEP] ...  negative\n",
              "2  What is the sentiment about the performance ? ...   neutral\n",
              "3  What is the sentiment about the design ? [SEP]...  positive\n",
              "4  What is the sentiment about the screen ? [SEP]...   neutral"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-740ab6d9-b62d-49e1-8524-f39206b8d209\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_pair</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the sentiment about the camera ? [SEP]...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the sentiment about the price ? [SEP] ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the sentiment about the performance ? ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the sentiment about the design ? [SEP]...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the sentiment about the screen ? [SEP]...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-740ab6d9-b62d-49e1-8524-f39206b8d209')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-740ab6d9-b62d-49e1-8524-f39206b8d209 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-740ab6d9-b62d-49e1-8524-f39206b8d209');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6444cf9-f3f0-44f4-b56f-85b3b1dfef9c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6444cf9-f3f0-44f4-b56f-85b3b1dfef9c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6444cf9-f3f0-44f4-b56f-85b3b1dfef9c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['input_pair', 'sentiment']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"input_pair\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is the sentiment about the price ? [SEP] I'm disappointed with the price.\",\n          \"What is the sentiment about the screen ? [SEP] Nothing special about the screen.\",\n          \"What is the sentiment about the performance ? [SEP] The performance is neither good nor bad.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode sentiment labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['sentiment'] = le.fit_transform(df['sentiment'])\n",
        "df[['input_pair', 'sentiment']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "py86liJRaQtY",
        "outputId": "3471f66f-c5ca-4d34-ea06-4db44ed5ce32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          input_pair  sentiment\n",
              "0  What is the sentiment about the camera ? [SEP]...          0\n",
              "1  What is the sentiment about the price ? [SEP] ...          0\n",
              "2  What is the sentiment about the performance ? ...          1\n",
              "3  What is the sentiment about the design ? [SEP]...          2\n",
              "4  What is the sentiment about the screen ? [SEP]...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24447cac-2c14-4b57-9f32-3c72dbb191e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_pair</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the sentiment about the camera ? [SEP]...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the sentiment about the price ? [SEP] ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the sentiment about the performance ? ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the sentiment about the design ? [SEP]...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the sentiment about the screen ? [SEP]...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24447cac-2c14-4b57-9f32-3c72dbb191e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24447cac-2c14-4b57-9f32-3c72dbb191e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24447cac-2c14-4b57-9f32-3c72dbb191e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1af6919a-5a4f-4540-bae5-8317b91f6d33\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1af6919a-5a4f-4540-bae5-8317b91f6d33')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1af6919a-5a4f-4540-bae5-8317b91f6d33 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['input_pair', 'sentiment']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"input_pair\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is the sentiment about the price ? [SEP] I'm disappointed with the price.\",\n          \"What is the sentiment about the screen ? [SEP] Nothing special about the screen.\",\n          \"What is the sentiment about the performance ? [SEP] The performance is neither good nor bad.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, test_texts, trainn_labels, test_labels = train_test_split(df['input_pair'], df['sentiment'], test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "1wjHfub2cGff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Huggingface Transformer: for encoding\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=64)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "9f533ab7eb1348478b9c77ae7a5c8d77",
            "f86006caa5574d229e0ca2bbdaec3438",
            "9fc7f35693ba4b85950a9316a44582d5",
            "5d48d2051f004c69a312b1ac2b9ef6c5",
            "20b915ddc70f4a398054504ad0f0d0b6",
            "c41f85b94448438ca72369301704f791",
            "1b74cd987f7b4b48bc533b8548455185",
            "ca2dab7d52d84bd6b9247c6e47e406fd",
            "de478aad0b504a3286261156a947a848",
            "ee68da2192644f79aaad332c3dfe9492",
            "c04dd9c9156d4b2194bfc6138b5d88d6",
            "0e124db89f1646838c4896b292f3b9f8",
            "74bedb075db54fa7aafcd9de216e4f64",
            "a81409c998174e65bb2aa4c2ff087070",
            "2a5c3836d3ec4bacbcbd5bf5fd0f0225",
            "a580d60f65894efe8710c968fbdd81a3",
            "6d4f57eb21a54b46bd85b8dda1dd0107",
            "2c38405a95f44607a1fcb78af6e7cdf5",
            "5bfeaf5da0284116895132858f1c2bdd",
            "eeaaa2ce400e4f47ba583b7441e36a06",
            "240f2aca6c7f47ceb4a5a30e74228365",
            "3cd4df20d7a243b68aff9e47816a01f1",
            "a2be1739952c4157a990e7026be01971",
            "aa402649de1b4c9d8aa78e296d34775c",
            "74551b36046a458c981538ca406742bf",
            "570a3e3627884aacb845658e25cb14c9",
            "2ad97a1feda34105bdb95d4c899a836d",
            "9b9cf35104f14aecb8a40eb71061ed7f",
            "dc44ae1907da413695b25bc6c503717c",
            "a5c30f604b9c430584b1373a854fa692",
            "9909d9897e6544a894e20cc714e1f866",
            "5fdf21bc57ea4651b188b431ea6b0fab",
            "03fdeb48d03b499e9e9956d3c6ccfd2d",
            "4f3e269d84044c8696180fbd04420687",
            "13cd8146ef96436884271118d8101199",
            "34b5727f9a7f4fe6b718e7605cdf0388",
            "3bdddfbe9898493181eb254dba454c32",
            "66043872589549feb18092163c1d0e82",
            "4cd86228e5dc4cf688654e366786080a",
            "e4c1734bec164b109d1eeb9e98c3f554",
            "b7e5acbffd6746f3b50fb3a8de507f36",
            "cd7b8e4d957c480f8c2408e68402cfc6",
            "cd314cee44124ba3adff91e8c57fdda6",
            "9ec3d5f7d82045b98764351774ad2a79"
          ]
        },
        "id": "fvzCjpp5cszE",
        "outputId": "1fed818f-9508-409c-a9f9-d6e973140a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f533ab7eb1348478b9c77ae7a5c8d77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e124db89f1646838c4896b292f3b9f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2be1739952c4157a990e7026be01971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f3e269d84044c8696180fbd04420687"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JWXnEbhdNrx",
        "outputId": "97a4142f-8d00-40a3-d887-b9669888849e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3811, 8510, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3811, 8510, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2498, 2569, 2055, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3811, 8510, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2498, 2569, 2055, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2498, 2569, 2055, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2498, 2569, 2055, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3811, 8510, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2498, 2569, 2055, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 5409, 3325, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2498, 2569, 2055, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3811, 8510, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 6581, 2836, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 6581, 4950, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3532, 6046, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 4950, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2498, 2569, 2055, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3811, 8510, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 6581, 2640, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2779, 2836, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 5409, 3325, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3811, 8510, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 2779, 3976, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 5409, 3325, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 5409, 3325, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2836, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 5409, 3325, 2007, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3811, 8510, 2007, 1996, 3976, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2498, 2569, 2055, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 6581, 6046, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 3532, 3976, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1996, 6046, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 3532, 3898, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3898, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 6581, 3898, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1045, 2293, 1996, 2836, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 6046, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 3976, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3811, 8510, 2007, 1996, 4950, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3811, 8510, 2007, 1996, 2640, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1996, 3976, 2003, 6659, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 3532, 2640, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 2779, 6046, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2779, 3898, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 3811, 8510, 2007, 1996, 6046, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 3532, 4950, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 2498, 2569, 2055, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 1045, 2293, 1996, 3976, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1996, 3898, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 1045, 2293, 1996, 3898, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 6046, 1029, 102, 1045, 2293, 1996, 6046, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 1005, 1049, 9364, 2007, 1996, 2640, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 1996, 2836, 2003, 4445, 2204, 4496, 2919, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 2498, 2569, 2055, 1996, 2836, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3898, 1029, 102, 5409, 3325, 2007, 1996, 3898, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1045, 2293, 1996, 2640, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1045, 2293, 1996, 4950, 1997, 2023, 4031, 1012, 102], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 1996, 2640, 2003, 6429, 999, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 2779, 4950, 1010, 2025, 2205, 2919, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 3976, 1029, 102, 6581, 3976, 1998, 4276, 1996, 3976, 1012, 102, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2836, 1029, 102, 3532, 2836, 1010, 2025, 3517, 1012, 102, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 4950, 1029, 102, 1996, 4950, 2003, 3100, 1012, 102, 0, 0, 0], [101, 2054, 2003, 1996, 15792, 2055, 1996, 2640, 1029, 102, 2779, 2640, 1010, 2025, 2205, 2919, 1012, 102, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Class to create dataset in desired format\n",
        "\n",
        "import torch\n",
        "\n",
        "class ABSADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} | {'labels': torch.tensor(self.labels[idx])}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ABSADataset(train_encodings, trainn_labels.tolist())\n",
        "test_dataset = ABSADataset(test_encodings, test_labels.tolist())"
      ],
      "metadata": {
        "id": "ZZwc7OnZdRht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um9kpfFzee81",
        "outputId": "3386077e-ea1e-4e2a-98e9-92604f9fb1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         6581,  2836,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         6581,  4950,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3532,  6046,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  4950,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         6581,  2640,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2779,  2836,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         2779,  3976,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2836,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  3976,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         6581,  6046,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         3532,  3976,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1996,  6046,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         3532,  3898,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3898,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         6581,  3898,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1045,  2293,  1996,  2836,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  6046,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  3976,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  4950,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  2640,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1996,  3976,  2003,  6659,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         3532,  2640,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         2779,  6046,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2779,  3898,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         3811,  8510,  2007,  1996,  6046,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         3532,  4950,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         1045,  2293,  1996,  3976,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1996,  3898,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         1045,  2293,  1996,  3898,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  6046,  1029,   102,\n",
            "         1045,  2293,  1996,  6046,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  1005,  1049,  9364,  2007,  1996,  2640,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         1996,  2836,  2003,  4445,  2204,  4496,  2919,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         2498,  2569,  2055,  1996,  2836,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3898,  1029,   102,\n",
            "         5409,  3325,  2007,  1996,  3898,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1045,  2293,  1996,  2640,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1045,  2293,  1996,  4950,  1997,  2023,  4031,  1012,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         1996,  2640,  2003,  6429,   999,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         2779,  4950,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  3976,  1029,   102,\n",
            "         6581,  3976,  1998,  4276,  1996,  3976,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(2)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2836,  1029,   102,\n",
            "         3532,  2836,  1010,  2025,  3517,  1012,   102,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]), 'labels': tensor(0)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  4950,  1029,   102,\n",
            "         1996,  4950,  2003,  3100,  1012,   102,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]), 'labels': tensor(1)}, {'input_ids': tensor([  101,  2054,  2003,  1996, 15792,  2055,  1996,  2640,  1029,   102,\n",
            "         2779,  2640,  1010,  2025,  2205,  2919,  1012,   102,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]), 'labels': tensor(1)}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train BERT model with ABSA dataset\n",
        "\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './results',\n",
        "    num_train_epochs = 3,\n",
        "    per_device_train_batch_size = 16,\n",
        "    per_device_eval_batch_size = 64,\n",
        "    eval_strategy = 'epoch',\n",
        "    logging_dir = './logs'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "78b264c7770d4eefbcead709b6a2f814",
            "39c7e809dea643808d54c280ad4723a8",
            "3963b4495b4b429599e48f0b315a3f09",
            "9231180ae19f42e49d1ae0d4db61ca45",
            "e08ab94bde784c2496fe1cefd4c3a76b",
            "92fa2c1f20d14fa1b3789f8a4dc20420",
            "248b02c103a94df980d8f343a2bef538",
            "d4a31921af0849a88a7cc26fd497b415",
            "801d18f751404b3b85ae585e9476bc77",
            "6875783911cf4d5ab0be17a85eb88fe7",
            "a8f2d5cab0f84c25b42ef5e9ff88d096"
          ]
        },
        "id": "pWs5nnz4ejRf",
        "outputId": "16b41e7c-2d57-4a85-f2ed-3261112d960e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b264c7770d4eefbcead709b6a2f814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "d0aCOSgzgJkG",
        "outputId": "06807523-1e8f-4eff-91de-730d047b6e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mishasarangi\u001b[0m (\u001b[33mishasarangi-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "creating run (0.0s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250921_140101-zhkqmht8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ishasarangi-student/huggingface/runs/zhkqmht8' target=\"_blank\">treasured-violet-1</a></strong> to <a href='https://wandb.ai/ishasarangi-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ishasarangi-student/huggingface' target=\"_blank\">https://wandb.ai/ishasarangi-student/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ishasarangi-student/huggingface/runs/zhkqmht8' target=\"_blank\">https://wandb.ai/ishasarangi-student/huggingface/runs/zhkqmht8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='151' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 11:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.009910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.002556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/4 : < :]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the sentiments\n",
        "def pred_aspect_sentiment(aspect, sentence):\n",
        "    input_text = f\"What is the sentiment about the {aspect} ? [SEP] {sentence}\"\n",
        "    inputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True)\n",
        "    outputs = model(**inputs)\n",
        "    pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return le.inverse_transform([pred])[0]"
      ],
      "metadata": {
        "id": "uwuwemxBgdwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_aspect_sentiment(\"battery\", 'The battery life is wonderful'))"
      ],
      "metadata": {
        "id": "MBV-aM02lDhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Huggingface Transformer Pipeline"
      ],
      "metadata": {
        "id": "rkCUeH_wlP0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('text-classification', model='yangheng/deberta-v3-base-absa-v1.1')\n",
        "\n",
        "#sample_text=\"The battery life is amazing, but the screen is poor\"\n",
        "sample_text=\"The battery life is ok, but the screen is poor\"\n",
        "#\"The battery life is amazing, but the screen is poor[SEP]screen\"  text pair\n",
        "result_screen=classifier(sample_text,text_pair='screen')\n",
        "result_battery=classifier(sample_text,text_pair='battery')\n",
        "\n",
        "print(f\"Aspect:screen sentiment:\",result_screen)\n",
        "print(f\"Aspect:battery sentiment:\",result_battery)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "56399a1a67e9441d9ba32e65b515f224",
            "223d25a13a2943e58a2ed04952df8c49",
            "27b4c1b7c1504179a7b213bb6f879d0a",
            "ff9a5d98e17e4c71ac80d9e7abb2f64a",
            "5eaeafc34f4a4034a951295f9f0aff36",
            "38f15cfa8ad54c0fbeaa0fa6a9017a61",
            "5880fc7f6a2b400786ae726620f7ba0f",
            "87801c4aa1184a498c4eed8e717016d4",
            "fa0fb66660a945cd814ed24863e73cdd",
            "337fef1191d24ad9be7ae71a4a5eeb3b",
            "6d188f1183234cad91ddb7f3a3305016",
            "ee773e54027b491d9e76537f84cf067c",
            "7a13efa9fddc4ade8bd797c03b3979db",
            "986765e390a64bc8854d26901d8fd070",
            "fe18a3f8e9b246fa91faa5b6f6115f03",
            "06a33f4a30d649c7bdff0deceb46fdf5",
            "bd4682bb960a4bd3922423805cc5c099",
            "b2ab4f4ff105457291387481778f6c3e",
            "3378aa1791b54f9baf60e8b835fde13a",
            "4657fe3a3fe2424ebc67cc61b81f95d1",
            "dd03dcc3bfa64f8ab15be073285f5c7b",
            "c8f4b4e1027a46659e5ec1674e5e9c99",
            "8ee22e4d957943ac9459acfc0fefa4c2",
            "0a8aaee9a41045f388f23a84d7171f8c",
            "4744affb2ddc4cb7bc4ce275e0dc63d8",
            "f94be7352e734970a6b7b6c6229eb25a",
            "541159f151474abba4bbd12c4fff185e",
            "0be5c8e1f39f4c9bb96a8b76455ae680",
            "cfd5edd5e7714de38712ede6c1e07728",
            "e4e42b1d990246178a58352a8eeb5fd6",
            "25d6c1ab74064b43b1c158c62e2dbcd3",
            "3825c53c6cd240fb82fe124cd270c85e",
            "f9d342d42bde43cbac8d90007effdcd9",
            "db49a09d0bb945838ee4316d7351114a",
            "9b9420392c3348bc9e97d00ab1366e65",
            "cb87cbea21264eabaa8620f2c0453afc",
            "73d237d8fa00422d85ecd49e65b16ccc",
            "0da1e67897ab496187708bd61335b3ed",
            "87314612a7414e5d9ee7b3aae47e35fc",
            "5e2e802020894eabb9238dce054f64de",
            "1b73b4ec8fa0433aaf8a5b2d4e04c6f3",
            "f69267c135614a9ba391cc2ab662ee43",
            "767afe5d4f4946ed93ae9ad06d6ff8ac",
            "32897fa3efa1487c8b85f43855451ab7",
            "2b50ba8f796645f29986c0f4be46d978",
            "76e4455f15ce42af895c037221a684b4",
            "b40f502029e242799e8fde8773070975",
            "0fcbc732b3864be28e33479fe7970071",
            "b2181ac462664eaf96b843efd5960680",
            "a91e21acb5f74f19a3ac5e207f6f9b81",
            "51cafd0e3640442495cc0f0b40fb6ae6",
            "11f9eba54b934c17b65c756d9e551ce0",
            "1bd143d89aa349e3942d3b05883a1d24",
            "5851bde868624ccaa943a25d53f95c88",
            "9632bb86900744f9b03bdec7ea0604d2",
            "883660c4320248ef9515a48d835f8449",
            "1efc23ad4c674bf29c56c9522c2b2b82",
            "9dd558e9ed71403ead059444b9ed4a63",
            "f9f8568640384758b38720445aeadef2",
            "ee7c2318ec044fdeb30e994209a1e803",
            "217fe649434247a48f78fbeb0ac9f055",
            "a63b48d1115d4170bd9d26642d973193",
            "64a19f0da689407eac316dc1f8142462",
            "4094f978fd324dc3b9c81cc1326a14b5",
            "d5a9ac5131504f53987931fe5d26a44e",
            "1dcf14de1e5642bdbd38813596b32e23"
          ]
        },
        "id": "-RWSZmTNlTgr",
        "outputId": "44a8223f-a257-4f1f-d8c7-06bbbd9df471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56399a1a67e9441d9ba32e65b515f224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee773e54027b491d9e76537f84cf067c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/372 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ee22e4d957943ac9459acfc0fefa4c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db49a09d0bb945838ee4316d7351114a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/18.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b50ba8f796645f29986c0f4be46d978"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "883660c4320248ef9515a48d835f8449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect:screen sentiment: [{'label': 'Negative', 'score': 0.9960415363311768}]\n",
            "Aspect:battery sentiment: [{'label': 'Positive', 'score': 0.8149920701980591}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine tuning HF model\n",
        "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
        "import tensorflow as tf\n",
        "model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
        "\n",
        "#Load tokenizer and Tensorflow Model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
        "\n",
        "#Prepare input\n",
        "sentence = \"The battery life is amazing, but the screen is too dim.\"\n",
        "aspect = \"Battery Life\"\n",
        "inputs = tokenizer(f\"{sentence} [SEP] {aspect}\", return_tensors='tf')\n",
        "\n",
        "#Predict\n",
        "outputs = model(**inputs)\n",
        "probs = tf.nn.softmax(outputs.logits, axis=1)\n",
        "pred_class = tf.argmax(probs, axis=1).numpy()[0]\n",
        "\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "print(f\"Aspect: {aspect} | Sentiment: {labels[pred_class]} | Probabilities: {probs.numpy()[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FofHuC-pItH",
        "outputId": "c46612cd-0020-47c6-fa1b-67b55dc149c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDebertaV2ForSequenceClassification: ['deberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFDebertaV2ForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDebertaV2ForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDebertaV2ForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDebertaV2ForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect: Battery Life | Senteiment: Positive | Probabilities: [0.00162201 0.00114306 0.997235  ]\n"
          ]
        }
      ]
    }
  ]
}