{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0quD+cmWIuiRIriawtVZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaSarangi/Edureka_Notes/blob/main/Edureka_NLP_demo_Aug_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/13r1UjXLz3E_fPgOJckKAw-_DIHXsOFXP?usp=sharing"
      ],
      "metadata": {
        "id": "zHjkPJDqkmr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lnXSSyEAkl67"
      },
      "outputs": [],
      "source": [
        "#import NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91MEbsFolKwc",
        "outputId": "32c450b7-0172-44d3-fda2-f91213fda73d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample Text\n",
        "text=\"\"\"Artificial Intelligence (AI) is transforming the\n",
        "way businesses operate across the globe.\n",
        "From healthcare to finance, AI-powered systems are helping organizations improve efficiency,\n",
        "reduce costs, and make smarter decisions.\n",
        "For example, chatbots are providing customer support 24/7,\n",
        "while recommendation systems are personalizing shopping experiences for millions of users.\n",
        "Despite these benefits, experts warn about ethical concerns, such as data privacy and job displacement.\n",
        "Therefore, it is essential to balance innovation with responsibility when adopting AI technologies.\"\"\""
      ],
      "metadata": {
        "id": "0z0UBE2WlgHo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Tokenizer\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "\n",
        "for sen in sentences:\n",
        "    print(sen)\n",
        "\n",
        "print(len(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tFMywlilniO",
        "outputId": "8bdaed9a-5aad-4186-d485-d10ec9384193"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Artificial Intelligence (AI) is transforming the\\nway businesses operate across the globe.', 'From healthcare to finance, AI-powered systems are helping organizations improve efficiency,\\nreduce costs, and make smarter decisions.', 'For example, chatbots are providing customer support 24/7,\\nwhile recommendation systems are personalizing shopping experiences for millions of users.', 'Despite these benefits, experts warn about ethical concerns, such as data privacy and job displacement.', 'Therefore, it is essential to balance innovation with responsibility when adopting AI technologies.']\n",
            "Artificial Intelligence (AI) is transforming the\n",
            "way businesses operate across the globe.\n",
            "From healthcare to finance, AI-powered systems are helping organizations improve efficiency,\n",
            "reduce costs, and make smarter decisions.\n",
            "For example, chatbots are providing customer support 24/7,\n",
            "while recommendation systems are personalizing shopping experiences for millions of users.\n",
            "Despite these benefits, experts warn about ethical concerns, such as data privacy and job displacement.\n",
            "Therefore, it is essential to balance innovation with responsibility when adopting AI technologies.\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Tokenize\n",
        "words=word_tokenize(text)\n",
        "print(words)\n",
        "print(len(words))\n",
        "\n",
        "for word in words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH3qpQLel00U",
        "outputId": "cbbe9f9d-c90b-43ee-d310-8510ab2268b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Artificial', 'Intelligence', '(', 'AI', ')', 'is', 'transforming', 'the', 'way', 'businesses', 'operate', 'across', 'the', 'globe', '.', 'From', 'healthcare', 'to', 'finance', ',', 'AI-powered', 'systems', 'are', 'helping', 'organizations', 'improve', 'efficiency', ',', 'reduce', 'costs', ',', 'and', 'make', 'smarter', 'decisions', '.', 'For', 'example', ',', 'chatbots', 'are', 'providing', 'customer', 'support', '24/7', ',', 'while', 'recommendation', 'systems', 'are', 'personalizing', 'shopping', 'experiences', 'for', 'millions', 'of', 'users', '.', 'Despite', 'these', 'benefits', ',', 'experts', 'warn', 'about', 'ethical', 'concerns', ',', 'such', 'as', 'data', 'privacy', 'and', 'job', 'displacement', '.', 'Therefore', ',', 'it', 'is', 'essential', 'to', 'balance', 'innovation', 'with', 'responsibility', 'when', 'adopting', 'AI', 'technologies', '.']\n",
            "91\n",
            "Artificial\n",
            "Intelligence\n",
            "(\n",
            "AI\n",
            ")\n",
            "is\n",
            "transforming\n",
            "the\n",
            "way\n",
            "businesses\n",
            "operate\n",
            "across\n",
            "the\n",
            "globe\n",
            ".\n",
            "From\n",
            "healthcare\n",
            "to\n",
            "finance\n",
            ",\n",
            "AI-powered\n",
            "systems\n",
            "are\n",
            "helping\n",
            "organizations\n",
            "improve\n",
            "efficiency\n",
            ",\n",
            "reduce\n",
            "costs\n",
            ",\n",
            "and\n",
            "make\n",
            "smarter\n",
            "decisions\n",
            ".\n",
            "For\n",
            "example\n",
            ",\n",
            "chatbots\n",
            "are\n",
            "providing\n",
            "customer\n",
            "support\n",
            "24/7\n",
            ",\n",
            "while\n",
            "recommendation\n",
            "systems\n",
            "are\n",
            "personalizing\n",
            "shopping\n",
            "experiences\n",
            "for\n",
            "millions\n",
            "of\n",
            "users\n",
            ".\n",
            "Despite\n",
            "these\n",
            "benefits\n",
            ",\n",
            "experts\n",
            "warn\n",
            "about\n",
            "ethical\n",
            "concerns\n",
            ",\n",
            "such\n",
            "as\n",
            "data\n",
            "privacy\n",
            "and\n",
            "job\n",
            "displacement\n",
            ".\n",
            "Therefore\n",
            ",\n",
            "it\n",
            "is\n",
            "essential\n",
            "to\n",
            "balance\n",
            "innovation\n",
            "with\n",
            "responsibility\n",
            "when\n",
            "adopting\n",
            "AI\n",
            "technologies\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stop word Removal\n",
        "stop_words=set(stopwords.words('english'))\n",
        "print(stop_words)\n",
        "filtered_words=[word for word in words if word.lower() not in stop_words]  #word.casefold() will ignore the case\n",
        "print(filtered_words)\n",
        "print(len(filtered_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zB8LJ9bmAdm",
        "outputId": "2bd07f21-5a12-4eb2-9529-f1844c1b3130"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'himself', 'does', 'or', 't', 'about', 'don', 'with', 'ain', 'him', \"they're\", 'herself', 'while', 'further', 'an', \"she'd\", \"it's\", 'in', 'because', \"aren't\", 'had', 'whom', 'shan', 'should', 'then', \"wouldn't\", 've', 'most', \"haven't\", \"we'll\", \"you're\", \"couldn't\", \"doesn't\", 'any', \"shan't\", 'what', 'of', 'there', 'he', 'am', 'between', 'theirs', 'same', 'a', 'being', 'themselves', 'those', 'where', 'for', 'mustn', 'which', 'below', \"i'm\", \"wasn't\", \"don't\", \"he'd\", 'm', 'my', 'that', 'again', 'doing', 'out', 'have', \"you'd\", 'this', 'their', 'yours', 'haven', 'yourself', 'its', 'to', 'll', 'hasn', 'other', 'and', 'ourselves', 'under', 'each', \"shouldn't\", 'during', \"he'll\", 'than', \"didn't\", 'his', 'not', 'over', 'but', \"mustn't\", 'from', 'above', 'are', 'i', 'were', 'has', \"weren't\", 'more', \"we're\", \"i've\", 'isn', \"they'd\", \"you'll\", 'couldn', 'who', \"she's\", 'very', 'your', 'it', 'all', \"it'd\", 'no', 'me', 'only', \"you've\", 'too', 'wouldn', \"isn't\", 's', 'will', 'is', 'did', \"i'll\", 'into', 'doesn', 'mightn', 'just', \"we've\", 'few', \"it'll\", 'you', \"needn't\", 'aren', 'our', 'up', 'off', \"mightn't\", \"should've\", 'against', 'why', \"hasn't\", \"we'd\", 'weren', 'her', 'hers', \"i'd\", 'she', 'hadn', 'myself', 'having', 'needn', \"he's\", 'down', 're', 'they', 'now', 'shouldn', 'once', 'before', 'as', \"that'll\", 'do', 'was', 'by', \"they've\", 'here', 'ours', 'so', 'until', 'through', 'o', \"she'll\", \"won't\", 'y', 'didn', \"they'll\", 'd', 'some', 'such', 'been', 'both', 'nor', 'on', 'can', 'how', 'itself', 'them', 'when', 'after', \"hadn't\", 'wasn', 'won', 'yourselves', 'ma', 'own', 'these', 'the', 'be', 'we', 'at', 'if'}\n",
            "['Artificial', 'Intelligence', '(', 'AI', ')', 'transforming', 'way', 'businesses', 'operate', 'across', 'globe', '.', 'healthcare', 'finance', ',', 'AI-powered', 'systems', 'helping', 'organizations', 'improve', 'efficiency', ',', 'reduce', 'costs', ',', 'make', 'smarter', 'decisions', '.', 'example', ',', 'chatbots', 'providing', 'customer', 'support', '24/7', ',', 'recommendation', 'systems', 'personalizing', 'shopping', 'experiences', 'millions', 'users', '.', 'Despite', 'benefits', ',', 'experts', 'warn', 'ethical', 'concerns', ',', 'data', 'privacy', 'job', 'displacement', '.', 'Therefore', ',', 'essential', 'balance', 'innovation', 'responsibility', 'adopting', 'AI', 'technologies', '.']\n",
            "68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stemming"
      ],
      "metadata": {
        "id": "tN22P_fMmWSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "ps = PorterStemmer()\n",
        "stemmed_words = [ps.stem(word) for word in filtered_words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFidFTOqmX6S",
        "outputId": "e119c9f1-7483-497e-f760-b2ee67826603"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['artifici', 'intellig', '(', 'ai', ')', 'transform', 'way', 'busi', 'oper', 'across', 'globe', '.', 'healthcar', 'financ', ',', 'ai-pow', 'system', 'help', 'organ', 'improv', 'effici', ',', 'reduc', 'cost', ',', 'make', 'smarter', 'decis', '.', 'exampl', ',', 'chatbot', 'provid', 'custom', 'support', '24/7', ',', 'recommend', 'system', 'person', 'shop', 'experi', 'million', 'user', '.', 'despit', 'benefit', ',', 'expert', 'warn', 'ethic', 'concern', ',', 'data', 'privaci', 'job', 'displac', '.', 'therefor', ',', 'essenti', 'balanc', 'innov', 'respons', 'adopt', 'ai', 'technolog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in filtered_words:\n",
        "    print(words+\": \"+ps.stem(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmxQnFIPmjqB",
        "outputId": "b5881130-958b-4ddf-af5c-260173e73b16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial: artifici\n",
            "Intelligence: intellig\n",
            "(: (\n",
            "AI: ai\n",
            "): )\n",
            "transforming: transform\n",
            "way: way\n",
            "businesses: busi\n",
            "operate: oper\n",
            "across: across\n",
            "globe: globe\n",
            ".: .\n",
            "healthcare: healthcar\n",
            "finance: financ\n",
            ",: ,\n",
            "AI-powered: ai-pow\n",
            "systems: system\n",
            "helping: help\n",
            "organizations: organ\n",
            "improve: improv\n",
            "efficiency: effici\n",
            ",: ,\n",
            "reduce: reduc\n",
            "costs: cost\n",
            ",: ,\n",
            "make: make\n",
            "smarter: smarter\n",
            "decisions: decis\n",
            ".: .\n",
            "example: exampl\n",
            ",: ,\n",
            "chatbots: chatbot\n",
            "providing: provid\n",
            "customer: custom\n",
            "support: support\n",
            "24/7: 24/7\n",
            ",: ,\n",
            "recommendation: recommend\n",
            "systems: system\n",
            "personalizing: person\n",
            "shopping: shop\n",
            "experiences: experi\n",
            "millions: million\n",
            "users: user\n",
            ".: .\n",
            "Despite: despit\n",
            "benefits: benefit\n",
            ",: ,\n",
            "experts: expert\n",
            "warn: warn\n",
            "ethical: ethic\n",
            "concerns: concern\n",
            ",: ,\n",
            "data: data\n",
            "privacy: privaci\n",
            "job: job\n",
            "displacement: displac\n",
            ".: .\n",
            "Therefore: therefor\n",
            ",: ,\n",
            "essential: essenti\n",
            "balance: balanc\n",
            "innovation: innov\n",
            "responsibility: respons\n",
            "adopting: adopt\n",
            "AI: ai\n",
            "technologies: technolog\n",
            ".: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lancaster Stemmer\n",
        "ls = LancasterStemmer()\n",
        "stemmed_words = [ls.stem(word) for word in filtered_words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xNGgxQmnUPa",
        "outputId": "0b071bd9-57ed-40bb-fae4-aafcb32dbd9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['art', 'intellig', '(', 'ai', ')', 'transform', 'way', 'busy', 'op', 'across', 'glob', '.', 'healthc', 'fin', ',', 'ai-powered', 'system', 'help', 'org', 'improv', 'efficy', ',', 'reduc', 'cost', ',', 'mak', 'smart', 'decid', '.', 'exampl', ',', 'chatbot', 'provid', 'custom', 'support', '24/7', ',', 'recommend', 'system', 'person', 'shop', 'expery', 'mil', 'us', '.', 'despit', 'benefit', ',', 'expert', 'warn', 'eth', 'concern', ',', 'dat', 'priv', 'job', 'displac', '.', 'theref', ',', 'ess', 'bal', 'innov', 'respons', 'adopt', 'ai', 'technolog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in filtered_words:\n",
        "  print(words+\":\"+ls.stem(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6-sDL2Onh0K",
        "outputId": "b8bb0269-15aa-41a2-dace-520f30e8002f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial:art\n",
            "Intelligence:intellig\n",
            "(:(\n",
            "AI:ai\n",
            "):)\n",
            "transforming:transform\n",
            "way:way\n",
            "businesses:busy\n",
            "operate:op\n",
            "across:across\n",
            "globe:glob\n",
            ".:.\n",
            "healthcare:healthc\n",
            "finance:fin\n",
            ",:,\n",
            "AI-powered:ai-powered\n",
            "systems:system\n",
            "helping:help\n",
            "organizations:org\n",
            "improve:improv\n",
            "efficiency:efficy\n",
            ",:,\n",
            "reduce:reduc\n",
            "costs:cost\n",
            ",:,\n",
            "make:mak\n",
            "smarter:smart\n",
            "decisions:decid\n",
            ".:.\n",
            "example:exampl\n",
            ",:,\n",
            "chatbots:chatbot\n",
            "providing:provid\n",
            "customer:custom\n",
            "support:support\n",
            "24/7:24/7\n",
            ",:,\n",
            "recommendation:recommend\n",
            "systems:system\n",
            "personalizing:person\n",
            "shopping:shop\n",
            "experiences:expery\n",
            "millions:mil\n",
            "users:us\n",
            ".:.\n",
            "Despite:despit\n",
            "benefits:benefit\n",
            ",:,\n",
            "experts:expert\n",
            "warn:warn\n",
            "ethical:eth\n",
            "concerns:concern\n",
            ",:,\n",
            "data:dat\n",
            "privacy:priv\n",
            "job:job\n",
            "displacement:displac\n",
            ".:.\n",
            "Therefore:theref\n",
            ",:,\n",
            "essential:ess\n",
            "balance:bal\n",
            "innovation:innov\n",
            "responsibility:respons\n",
            "adopting:adopt\n",
            "AI:ai\n",
            "technologies:technolog\n",
            ".:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Snowball Stemmer: for multiple languages\n",
        "print(\" \".join(SnowballStemmer.languages))\n",
        "\n",
        "sample=\"Les √©tudiants aiment √©tudier les diff√©rentes √©tudes.\"\n",
        "\n",
        "sample = word_tokenize(sample)\n",
        "print(sample)\n",
        "\n",
        "ss = SnowballStemmer('french')\n",
        "stemmed_words = [ss.stem(word) for word in sample]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLkj06uLnpge",
        "outputId": "f58784b0-3da7-4a41-c030-90d55ffeb9d4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arabic danish dutch english finnish french german hungarian italian norwegian porter portuguese romanian russian spanish swedish\n",
            "['Les', '√©tudiants', 'aiment', '√©tudier', 'les', 'diff√©rentes', '√©tudes', '.']\n",
            "['le', '√©tudi', 'aiment', '√©tudi', 'le', 'diff√©rent', '√©tud', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss=SnowballStemmer('english')\n",
        "stemmed_words=[ss.stem(word) for word in filtered_words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29-YGDULn5DW",
        "outputId": "2d504371-a762-455f-aa7a-c4ff0331dd4c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['artifici', 'intellig', '(', 'ai', ')', 'transform', 'way', 'busi', 'oper', 'across', 'globe', '.', 'healthcar', 'financ', ',', 'ai-pow', 'system', 'help', 'organ', 'improv', 'effici', ',', 'reduc', 'cost', ',', 'make', 'smarter', 'decis', '.', 'exampl', ',', 'chatbot', 'provid', 'custom', 'support', '24/7', ',', 'recommend', 'system', 'person', 'shop', 'experi', 'million', 'user', '.', 'despit', 'benefit', ',', 'expert', 'warn', 'ethic', 'concern', ',', 'data', 'privaci', 'job', 'displac', '.', 'therefor', ',', 'essenti', 'balanc', 'innov', 'respons', 'adopt', 'ai', 'technolog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for words in filtered_words:\n",
        "  print(words+\":\"+ss.stem(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tAL1Bdvn6jT",
        "outputId": "7567948a-c57d-4ca0-b8e9-4b4c560a42ef"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial:artifici\n",
            "Intelligence:intellig\n",
            "(:(\n",
            "AI:ai\n",
            "):)\n",
            "transforming:transform\n",
            "way:way\n",
            "businesses:busi\n",
            "operate:oper\n",
            "across:across\n",
            "globe:globe\n",
            ".:.\n",
            "healthcare:healthcar\n",
            "finance:financ\n",
            ",:,\n",
            "AI-powered:ai-pow\n",
            "systems:system\n",
            "helping:help\n",
            "organizations:organ\n",
            "improve:improv\n",
            "efficiency:effici\n",
            ",:,\n",
            "reduce:reduc\n",
            "costs:cost\n",
            ",:,\n",
            "make:make\n",
            "smarter:smarter\n",
            "decisions:decis\n",
            ".:.\n",
            "example:exampl\n",
            ",:,\n",
            "chatbots:chatbot\n",
            "providing:provid\n",
            "customer:custom\n",
            "support:support\n",
            "24/7:24/7\n",
            ",:,\n",
            "recommendation:recommend\n",
            "systems:system\n",
            "personalizing:person\n",
            "shopping:shop\n",
            "experiences:experi\n",
            "millions:million\n",
            "users:user\n",
            ".:.\n",
            "Despite:despit\n",
            "benefits:benefit\n",
            ",:,\n",
            "experts:expert\n",
            "warn:warn\n",
            "ethical:ethic\n",
            "concerns:concern\n",
            ",:,\n",
            "data:data\n",
            "privacy:privaci\n",
            "job:job\n",
            "displacement:displac\n",
            ".:.\n",
            "Therefore:therefor\n",
            ",:,\n",
            "essential:essenti\n",
            "balance:balanc\n",
            "innovation:innov\n",
            "responsibility:respons\n",
            "adopting:adopt\n",
            "AI:ai\n",
            "technologies:technolog\n",
            ".:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lemmatization: WordNetLemmatizer"
      ],
      "metadata": {
        "id": "qmX-9QFwn9AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "stemmed_word = ps.stem(\"Study\")\n",
        "lemmatized_word = lemmatizer.lemmatize(\"Study\")\n",
        "print(\"Stemmed Output: \", stemmed_word)\n",
        "print(\"Lemmatized Output: \", lemmatized_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQW29Jp0oBAL",
        "outputId": "d29eaacc-5a0b-4592-915d-23ca9b87720e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Output:  studi\n",
            "Lemmatized Output:  Study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words=[lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "stemmed_words=[ps.stem(word) for word in filtered_words]\n",
        "\n",
        "for i in range(len(filtered_words)):\n",
        "  print(filtered_words[i]+\" Lemma:\"+lemmatized_words[i]+\" Stem:\"+stemmed_words[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc90nMdyoVFR",
        "outputId": "0ed293f2-4e8c-4f36-df05-1998faa2d8f4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Lemma:Artificial Stem:artifici\n",
            "Intelligence Lemma:Intelligence Stem:intellig\n",
            "( Lemma:( Stem:(\n",
            "AI Lemma:AI Stem:ai\n",
            ") Lemma:) Stem:)\n",
            "transforming Lemma:transforming Stem:transform\n",
            "way Lemma:way Stem:way\n",
            "businesses Lemma:business Stem:busi\n",
            "operate Lemma:operate Stem:oper\n",
            "across Lemma:across Stem:across\n",
            "globe Lemma:globe Stem:globe\n",
            ". Lemma:. Stem:.\n",
            "healthcare Lemma:healthcare Stem:healthcar\n",
            "finance Lemma:finance Stem:financ\n",
            ", Lemma:, Stem:,\n",
            "AI-powered Lemma:AI-powered Stem:ai-pow\n",
            "systems Lemma:system Stem:system\n",
            "helping Lemma:helping Stem:help\n",
            "organizations Lemma:organization Stem:organ\n",
            "improve Lemma:improve Stem:improv\n",
            "efficiency Lemma:efficiency Stem:effici\n",
            ", Lemma:, Stem:,\n",
            "reduce Lemma:reduce Stem:reduc\n",
            "costs Lemma:cost Stem:cost\n",
            ", Lemma:, Stem:,\n",
            "make Lemma:make Stem:make\n",
            "smarter Lemma:smarter Stem:smarter\n",
            "decisions Lemma:decision Stem:decis\n",
            ". Lemma:. Stem:.\n",
            "example Lemma:example Stem:exampl\n",
            ", Lemma:, Stem:,\n",
            "chatbots Lemma:chatbots Stem:chatbot\n",
            "providing Lemma:providing Stem:provid\n",
            "customer Lemma:customer Stem:custom\n",
            "support Lemma:support Stem:support\n",
            "24/7 Lemma:24/7 Stem:24/7\n",
            ", Lemma:, Stem:,\n",
            "recommendation Lemma:recommendation Stem:recommend\n",
            "systems Lemma:system Stem:system\n",
            "personalizing Lemma:personalizing Stem:person\n",
            "shopping Lemma:shopping Stem:shop\n",
            "experiences Lemma:experience Stem:experi\n",
            "millions Lemma:million Stem:million\n",
            "users Lemma:user Stem:user\n",
            ". Lemma:. Stem:.\n",
            "Despite Lemma:Despite Stem:despit\n",
            "benefits Lemma:benefit Stem:benefit\n",
            ", Lemma:, Stem:,\n",
            "experts Lemma:expert Stem:expert\n",
            "warn Lemma:warn Stem:warn\n",
            "ethical Lemma:ethical Stem:ethic\n",
            "concerns Lemma:concern Stem:concern\n",
            ", Lemma:, Stem:,\n",
            "data Lemma:data Stem:data\n",
            "privacy Lemma:privacy Stem:privaci\n",
            "job Lemma:job Stem:job\n",
            "displacement Lemma:displacement Stem:displac\n",
            ". Lemma:. Stem:.\n",
            "Therefore Lemma:Therefore Stem:therefor\n",
            ", Lemma:, Stem:,\n",
            "essential Lemma:essential Stem:essenti\n",
            "balance Lemma:balance Stem:balanc\n",
            "innovation Lemma:innovation Stem:innov\n",
            "responsibility Lemma:responsibility Stem:respons\n",
            "adopting Lemma:adopting Stem:adopt\n",
            "AI Lemma:AI Stem:ai\n",
            "technologies Lemma:technology Stem:technolog\n",
            ". Lemma:. Stem:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Handling Special Characters"
      ],
      "metadata": {
        "id": "8w8qVSnUoYW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "special_chars = set(string.punctuation)\n",
        "print(special_chars)\n",
        "\n",
        "lst = [\":)\", \":(\"]\n",
        "special_chars.update(lst)\n",
        "print(special_chars)\n",
        "\n",
        "filtered_words = [word for word in filtered_words if word not in list(special_chars)]\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFgFb8zVobDA",
        "outputId": "c6d3f2af-82b9-4ab9-cb01-89c35baa4e1f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{',', '<', '_', '+', '#', '/', '-', '}', \"'\", '.', '{', '*', '&', '?', '\"', ']', '$', '%', '`', '(', '=', ';', '@', '\\\\', '!', ':', '^', '|', ')', '>', '~', '['}\n",
            "{',', '<', '_', '+', '#', '/', '-', '}', \"'\", '.', '{', '*', '&', '?', '\"', ':)', ']', '$', '%', '`', '(', '=', ';', '@', ':(', '\\\\', '!', ':', '^', '|', ')', '>', '~', '['}\n",
            "['Artificial', 'Intelligence', 'AI', 'transforming', 'way', 'businesses', 'operate', 'across', 'globe', 'healthcare', 'finance', 'AI-powered', 'systems', 'helping', 'organizations', 'improve', 'efficiency', 'reduce', 'costs', 'make', 'smarter', 'decisions', 'example', 'chatbots', 'providing', 'customer', 'support', '24/7', 'recommendation', 'systems', 'personalizing', 'shopping', 'experiences', 'millions', 'users', 'Despite', 'benefits', 'experts', 'warn', 'ethical', 'concerns', 'data', 'privacy', 'job', 'displacement', 'Therefore', 'essential', 'balance', 'innovation', 'responsibility', 'adopting', 'AI', 'technologies']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting into Lemmas\n",
        "filtered_words = [lemmatizer.lemmatize(word) for word in filtered_words]"
      ],
      "metadata": {
        "id": "Q7OiQWD8o0Jh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in filtered_words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nswKbcj6o-OU",
        "outputId": "66eb140d-8e97-4e7c-c486-1651b27f29fa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial\n",
            "Intelligence\n",
            "AI\n",
            "transforming\n",
            "way\n",
            "business\n",
            "operate\n",
            "across\n",
            "globe\n",
            "healthcare\n",
            "finance\n",
            "AI-powered\n",
            "system\n",
            "helping\n",
            "organization\n",
            "improve\n",
            "efficiency\n",
            "reduce\n",
            "cost\n",
            "make\n",
            "smarter\n",
            "decision\n",
            "example\n",
            "chatbots\n",
            "providing\n",
            "customer\n",
            "support\n",
            "24/7\n",
            "recommendation\n",
            "system\n",
            "personalizing\n",
            "shopping\n",
            "experience\n",
            "million\n",
            "user\n",
            "Despite\n",
            "benefit\n",
            "expert\n",
            "warn\n",
            "ethical\n",
            "concern\n",
            "data\n",
            "privacy\n",
            "job\n",
            "displacement\n",
            "Therefore\n",
            "essential\n",
            "balance\n",
            "innovation\n",
            "responsibility\n",
            "adopting\n",
            "AI\n",
            "technology\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part of Speech Tagging"
      ],
      "metadata": {
        "id": "CPq_jYy0pDAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Resource for POS tagging for English Language\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOsE3Oi6pGCq",
        "outputId": "24a96d0e-0f34-44f8-c9d0-7ce6a927cde7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_with_pos=nltk.pos_tag(filtered_words)\n",
        "\n",
        "for token, pos_tag in tokens_with_pos:\n",
        "  print(f\"{token}:{pos_tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuUVQzecpHTj",
        "outputId": "dc8902cc-c340-4d58-83da-3a6e8bd18b49"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial:JJ\n",
            "Intelligence:NNP\n",
            "AI:NNP\n",
            "transforming:VBG\n",
            "way:NN\n",
            "business:NN\n",
            "operate:VBP\n",
            "across:IN\n",
            "globe:NN\n",
            "healthcare:NN\n",
            "finance:NN\n",
            "AI-powered:NNP\n",
            "system:NN\n",
            "helping:VBG\n",
            "organization:NN\n",
            "improve:VB\n",
            "efficiency:NN\n",
            "reduce:VB\n",
            "cost:NN\n",
            "make:VBP\n",
            "smarter:JJR\n",
            "decision:NN\n",
            "example:NN\n",
            "chatbots:NNS\n",
            "providing:VBG\n",
            "customer:NN\n",
            "support:NN\n",
            "24/7:CD\n",
            "recommendation:NN\n",
            "system:NN\n",
            "personalizing:VBG\n",
            "shopping:VBG\n",
            "experience:NN\n",
            "million:CD\n",
            "user:IN\n",
            "Despite:IN\n",
            "benefit:NN\n",
            "expert:NN\n",
            "warn:VBP\n",
            "ethical:JJ\n",
            "concern:NN\n",
            "data:NNS\n",
            "privacy:NN\n",
            "job:NN\n",
            "displacement:NN\n",
            "Therefore:NNP\n",
            "essential:JJ\n",
            "balance:NN\n",
            "innovation:NN\n",
            "responsibility:NN\n",
            "adopting:VBG\n",
            "AI:NNP\n",
            "technology:NN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CC coordinating conjunction CD cardinal digit DT determiner EX existential there (like: \"there is\" ... think of it like \"there exists\") FW foreign word IN preposition/subordinating conjunction JJ adjective - 'big' JJR adjective, comparative - 'bigger' JJS adjective, superlative - 'biggest' LS list marker 1) MD modal - could, will NN noun, singular '- desk' NNS noun plural - 'desks' NNP proper noun, singular - 'Harrison' NNPS proper noun, plural - 'Americans' PDT predeterminer - 'all the kids' POS possessive ending parent's PRP personal pronoun - I, he, she PRP possessivepronoun‚àímy,his,hersRBadverb‚àívery,silently,RBRadverb,comparative‚àíbetterRBSadverb,superlative‚àíbestRPparticle‚àígiveupTO‚àítogo‚Ä≤to‚Ä≤thestore.UHinterjection‚àíerrrrrrrrmVBverb,baseform‚àítakeVBDverb,pasttense‚àítookVBGverb,gerund/presentparticiple‚àítakingVBNverb,pastparticiple‚àítakenVBPverb,sing.present,non‚àí3d‚àítakeVBZverb,3rdpersonsing.present‚àítakesWDTwh‚àídeterminer‚àíwhichWPwh‚àípronoun‚àíwho,whatWP  possessive wh-pronoun, eg- whose WRB wh-adverb, eg- where, when"
      ],
      "metadata": {
        "id": "TSVpuqhlpL06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Messy data, full of emojis, Hashtags, URLs, @"
      ],
      "metadata": {
        "id": "rGCNUjf-4Zax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/multilingual_twitter_dataset.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "jDgsYEFrpN67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "f66732e3-e218-4349-e085-b14152914d0e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  username location  gender  age  \\\n",
              "0   user_1    India  Female   43   \n",
              "1   user_2   France    Male   26   \n",
              "2   user_3  Germany   Other   30   \n",
              "3   user_4  Germany  Female   38   \n",
              "4   user_5    Japan  Female   39   \n",
              "5   user_6      USA    Male   45   \n",
              "6   user_7   France   Other   24   \n",
              "7   user_8   Brazil  Female   47   \n",
              "8   user_9    Egypt   Other   36   \n",
              "9  user_10      USA    Male   54   \n",
              "\n",
              "                                           tweet  \n",
              "0  Can't believe this happened... lol :D #fail üòÖ  \n",
              "1                                     ‰ø°„Åò„Çâ„Çå„Å™„ÅÑ‚Ä¶ üò≠üíî  \n",
              "2                 Das ist fantastisch üòçüíØ! #Liebe  \n",
              "3  Can't believe this happened... lol :D #fail üòÖ  \n",
              "4                  ¬°Esto es perfecto! üòäüíÉ #fiesta  \n",
              "5                          –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—É–ø–µ—Ä! üî•üî•üî•  \n",
              "6                Ich kann das nicht glauben!! üò†üò§  \n",
              "7               Je n‚Äôaime pas √ßa... :( #triste üò¢  \n",
              "8                     Ini luar biasa! üòçüëè #senang  \n",
              "9               Je n‚Äôaime pas √ßa... :( #triste üò¢  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7073f784-2724-4007-86d4-00edaf89fe75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>location</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user_1</td>\n",
              "      <td>India</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>Can't believe this happened... lol :D #fail üòÖ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user_2</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>26</td>\n",
              "      <td>‰ø°„Åò„Çâ„Çå„Å™„ÅÑ‚Ä¶ üò≠üíî</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user_3</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Other</td>\n",
              "      <td>30</td>\n",
              "      <td>Das ist fantastisch üòçüíØ! #Liebe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user_4</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>38</td>\n",
              "      <td>Can't believe this happened... lol :D #fail üòÖ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user_5</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>¬°Esto es perfecto! üòäüíÉ #fiesta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>user_6</td>\n",
              "      <td>USA</td>\n",
              "      <td>Male</td>\n",
              "      <td>45</td>\n",
              "      <td>–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—É–ø–µ—Ä! üî•üî•üî•</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>user_7</td>\n",
              "      <td>France</td>\n",
              "      <td>Other</td>\n",
              "      <td>24</td>\n",
              "      <td>Ich kann das nicht glauben!! üò†üò§</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>user_8</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>Female</td>\n",
              "      <td>47</td>\n",
              "      <td>Je n‚Äôaime pas √ßa... :( #triste üò¢</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>user_9</td>\n",
              "      <td>Egypt</td>\n",
              "      <td>Other</td>\n",
              "      <td>36</td>\n",
              "      <td>Ini luar biasa! üòçüëè #senang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>user_10</td>\n",
              "      <td>USA</td>\n",
              "      <td>Male</td>\n",
              "      <td>54</td>\n",
              "      <td>Je n‚Äôaime pas √ßa... :( #triste üò¢</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7073f784-2724-4007-86d4-00edaf89fe75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7073f784-2724-4007-86d4-00edaf89fe75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7073f784-2724-4007-86d4-00edaf89fe75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b9bbc1c5-24d8-41df-acb2-5ec6df5bfa04\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9bbc1c5-24d8-41df-acb2-5ec6df5bfa04')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b9bbc1c5-24d8-41df-acb2-5ec6df5bfa04 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"user_84\",\n          \"user_54\",\n          \"user_71\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Indonesia\",\n          \"France\",\n          \"Brazil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Female\",\n          \"Male\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 18,\n        \"max\": 60,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          18,\n          34,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Can't believe this happened... lol :D #fail \\ud83d\\ude05\",\n          \"I love this! \\ud83d\\ude0d Soooo good!!! #awesome \\ud83d\\ude0a\",\n          \"Gak suka banget \\ud83d\\ude12\\ud83d\\ude24 #kesal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect spacy ftfy contractions emoji Tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8dSuRAZ5LxC",
        "outputId": "7f29d331-26b4-4d71-8972-0053f8c9217d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (6.3.1)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.12/dist-packages (0.1.73)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (2.14.1)\n",
            "Requirement already satisfied: Tokenizer in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.16.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.12/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import ftfy\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from langdetect import detect\n",
        "import spacy\n",
        "import emoji\n",
        "\n",
        "#Download necessary nltk resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBwYm3aS6Xvg",
        "outputId": "0b1e06b0-47d6-489c-eb31-cb05cca08f79"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Detect language\n",
        "df['language']=df['tweet'].apply(lambda x:detect(x))\n",
        "print(df['language'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5MMd6yA7Mij",
        "outputId": "d889dbe6-b16a-4960-bf63-719d1384dda2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language\n",
            "de    14\n",
            "id    14\n",
            "fr    13\n",
            "pt    13\n",
            "ja    12\n",
            "en     8\n",
            "ru     8\n",
            "hi     7\n",
            "es     6\n",
            "ur     4\n",
            "ar     1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter English Tweets\n",
        "df_en = df[df['language']=='en'].reset_index(drop=True)\n",
        "print(\"English Tweets:\\n\", df_en[['tweet']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtwry2LL8jhL",
        "outputId": "ef3aff0b-3b29-49db-ac25-8cd502e9d3b1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Tweets:\n",
            "                                            tweet\n",
            "0  Can't believe this happened... lol :D #fail üòÖ\n",
            "1  Can't believe this happened... lol :D #fail üòÖ\n",
            "2  Can't believe this happened... lol :D #fail üòÖ\n",
            "3        I love this! üòç Soooo good!!! #awesome üòä\n",
            "4  Can't believe this happened... lol :D #fail üòÖ\n",
            "5        I love this! üòç Soooo good!!! #awesome üòä\n",
            "6        I love this! üòç Soooo good!!! #awesome üòä\n",
            "7  Can't believe this happened... lol :D #fail üòÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stopword removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df_en['cleaned']=df_en['tweet'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))\n",
        "\n",
        "print(\"After stopwords:\\n\", df_en['cleaned'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JFgHCAe89-4",
        "outputId": "dd4412f3-b088-4870-9021-066c39efa576"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After stopwords:\n",
            " 0    Ca n't believe happened ... lol : D # fail üòÖ\n",
            "1    Ca n't believe happened ... lol : D # fail üòÖ\n",
            "2    Ca n't believe happened ... lol : D # fail üòÖ\n",
            "3         I love ! üòç Soooo good ! ! ! # awesome üòä\n",
            "4    Ca n't believe happened ... lol : D # fail üòÖ\n",
            "5         I love ! üòç Soooo good ! ! ! # awesome üòä\n",
            "6         I love ! üòç Soooo good ! ! ! # awesome üòä\n",
            "7    Ca n't believe happened ... lol : D # fail üòÖ\n",
            "Name: cleaned, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Noise(URLs, Mentions, Hashtags, Punctuations)\n",
        "def remove_noise(text):\n",
        "    text=re.sub(r'http\\S+|www\\S+','',text) #URLs\n",
        "    text=re.sub(r\"@\\S+\", \"\", text) #Mentions\n",
        "    text=re.sub(r\"#\\S+\", \"\", text) #Hashtags\n",
        "    text=re.sub(rf\"[{re.escape(string.punctuation)}]\", \"\", text) #Punctuations\n",
        "    return text\n",
        "\n",
        "df_en['cleaned'] = df_en['cleaned'].apply(remove_noise)\n",
        "print(\"After noise removal:\\n\", df_en['cleaned'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbSzv9W8-J56",
        "outputId": "ac671eab-655a-421b-93f2-dd114651ba45"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After noise removal:\n",
            " 0    Ca nt believe happened  lol  D  fail üòÖ\n",
            "1    Ca nt believe happened  lol  D  fail üòÖ\n",
            "2    Ca nt believe happened  lol  D  fail üòÖ\n",
            "3        I love  üòç Soooo good     awesome üòä\n",
            "4    Ca nt believe happened  lol  D  fail üòÖ\n",
            "5        I love  üòç Soooo good     awesome üòä\n",
            "6        I love  üòç Soooo good     awesome üòä\n",
            "7    Ca nt believe happened  lol  D  fail üòÖ\n",
            "Name: cleaned, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove emojis\n",
        "def remove_emojis(text):\n",
        "    return emoji.replace_emoji(text, '')\n",
        "\n",
        "df_en['cleaned'] = df_en['cleaned'].apply(remove_emojis)\n",
        "print(\"After emoji removal:\\n\", df_en['cleaned'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDTbWpcvAGkx",
        "outputId": "e6d1ebc2-f71b-4779-f8a5-f6226df86b0b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After emoji removal:\n",
            " 0    Ca nt believe happened  lol  D  fail \n",
            "1    Ca nt believe happened  lol  D  fail \n",
            "2    Ca nt believe happened  lol  D  fail \n",
            "3         I love   Soooo good     awesome \n",
            "4    Ca nt believe happened  lol  D  fail \n",
            "5         I love   Soooo good     awesome \n",
            "6         I love   Soooo good     awesome \n",
            "7    Ca nt believe happened  lol  D  fail \n",
            "Name: cleaned, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handle contractions\n",
        "def handle_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "df_en['cleaned'] = df_en['cleaned'].apply(handle_contractions)\n",
        "print(\"After contractions:\\n\", df_en['cleaned'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InJl3bAOCLhz",
        "outputId": "71e62759-2df5-484c-cd20-cfbc5d7237f3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After contractions:\n",
            " 0    Ca nt believe happened  lol  D  fail \n",
            "1    Ca nt believe happened  lol  D  fail \n",
            "2    Ca nt believe happened  lol  D  fail \n",
            "3         I love   Soooo good     awesome \n",
            "4    Ca nt believe happened  lol  D  fail \n",
            "5         I love   Soooo good     awesome \n",
            "6         I love   Soooo good     awesome \n",
            "7    Ca nt believe happened  lol  D  fail \n",
            "Name: cleaned, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Processed output:\\n\",df_en[['tweet','cleaned']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uS3aJX4DAiH",
        "outputId": "3ffdcf67-bea1-49cf-b6a4-19eb19cc515d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Processed output:\n",
            "                                            tweet  \\\n",
            "0  Can't believe this happened... lol :D #fail üòÖ   \n",
            "1  Can't believe this happened... lol :D #fail üòÖ   \n",
            "2  Can't believe this happened... lol :D #fail üòÖ   \n",
            "3        I love this! üòç Soooo good!!! #awesome üòä   \n",
            "4  Can't believe this happened... lol :D #fail üòÖ   \n",
            "5        I love this! üòç Soooo good!!! #awesome üòä   \n",
            "6        I love this! üòç Soooo good!!! #awesome üòä   \n",
            "7  Can't believe this happened... lol :D #fail üòÖ   \n",
            "\n",
            "                                 cleaned  \n",
            "0  Ca nt believe happened  lol  D  fail   \n",
            "1  Ca nt believe happened  lol  D  fail   \n",
            "2  Ca nt believe happened  lol  D  fail   \n",
            "3       I love   Soooo good     awesome   \n",
            "4  Ca nt believe happened  lol  D  fail   \n",
            "5       I love   Soooo good     awesome   \n",
            "6       I love   Soooo good     awesome   \n",
            "7  Ca nt believe happened  lol  D  fail   \n"
          ]
        }
      ]
    }
  ]
}